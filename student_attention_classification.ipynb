{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowriks12/student-attentiveness-classification/blob/main/student_attention_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7nLuv8RfXpP"
      },
      "outputs": [],
      "source": [
        "# Installs\n",
        "!pip install imageai\n",
        "!pip install tensorflow\n",
        "!pip install pickle-mixin\n",
        "!pip install mediapipe\n",
        "!pip install scikit-learn==1.0\n",
        "# !python -m pip uninstall matplotlib\n",
        "!pip install matplotlib==3.1.3\n",
        "!pip install tensorflow-object-detection-api\n",
        "!pip install dataframe-image\n",
        "!pip install python-docx\n",
        "!pip install pydub flask_ngrok flask_cors\n",
        "!pip install shutil\n",
        "!apt-get install xattr > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l7TiciLzNNi",
        "outputId": "922367f3-3a3a-4e5d-f053-57e926274489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Module\n",
        "!pip install pydrive                             # Package to use Google Drive API - not installed in Colab VM by default\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "\n",
        "from google.colab import auth                    # Other necessary packages\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()                         # Follow prompt in the authorization process\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "\n",
        "drive = GoogleDrive(gauth)\n",
        "# https://drive.google.com/file/d/1UXpKfXMFVgNYDH5j3K-RZkWLTbGLKblv/view?usp=sharing\n",
        "your_module = drive.CreateFile({\"id\": \"1UXpKfXMFVgNYDH5j3K-RZkWLTbGLKblv\"})   # \"your_module_file_id\" is the part after \"id=\" in the shareable link\n",
        "your_module.GetContentFile(\"PoseModule.py\")          # Save the .py module file to Colab VM"
      ],
      "metadata": {
        "id": "uWPnjKmYfhMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "import pickle\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import PoseModule as pm\n",
        "import pandas as pd\n",
        "import csv\n",
        "from object_detection.utils import visualization_utils as vis_utils\n",
        "# from PyPDF2 import PdfFileWriter\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "# from pandas.table.plotting import table\n",
        "from pandas.plotting import table \n",
        "execution_path = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "download_path = \"/content/drive/MyDrive/Colab Notebooks/downloads\"\n",
        "upload_path = \"/content/drive/MyDrive/Colab Notebooks/uploads\"\n",
        "%matplotlib inline\n",
        "import dataframe_image as dfi\n",
        "import docx\n",
        "from docx.shared import Inches\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "eQwNUnN9fkmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pose Classification Module\n",
        "def multiPoseClassifier():\n",
        "  detector = ObjectDetection()\n",
        "  detector.setModelTypeAsRetinaNet()\n",
        "  \n",
        "  detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.1.0.h5\"))\n",
        "  detector.loadModel()\n",
        "  poseDetector = pm.PoseDetector()\n",
        "  # poseDetector.poseClassifier()\n",
        "  # loaded_model = pickle.load(open(os.path.join(execution_path , 'knn_r_pca_pipe.sav'), 'rb'))\n",
        "  loaded_model = pickle.load(open(os.path.join(execution_path , 'rf_pipe_pickle.sav'), 'rb'))\n",
        "  custom_objects = detector.CustomObjects(person=True)\n",
        "  # folder_path = '/content/drive/MyDrive/Colab Notebooks/Thesis-object-detection/frames'\n",
        "\n",
        "  output = []\n",
        "  count = 0\n",
        "  one_frame_each = 100\n",
        "  folder_name = \"test2\"\n",
        "  videofile = os.path.join(upload_path,\"test.mov\")\n",
        "  vidcap = cv2.VideoCapture(videofile)\n",
        "\n",
        "  success = True\n",
        "  while success:\n",
        "      if (count % one_frame_each == 0):                                   # checks frame number and keeps one_frame_each          \n",
        "          success,image = vidcap.read() \n",
        "          print(count)\n",
        "          # image = cv2.imread(os.path.join(folder_path , filename))\n",
        "          file_name = 'frame' + str(count)+ '.png'\n",
        "          cv2.imwrite(os.path.join(execution_path, folder_name, file_name), image)\n",
        "          op_img = \"temp.jpg\"                                # reads next frame           \n",
        "          detections = detector.detectCustomObjectsFromImage(custom_objects=custom_objects, input_image= os.path.join(execution_path, folder_name, file_name), output_image_path=os.path.join(execution_path , op_img), minimum_percentage_probability=30)\n",
        "          person_count = 0\n",
        "          img = Image.open(os.path.join(execution_path , folder_name, file_name))\n",
        "          for eachObject in detections:\n",
        "            person_count += 1\n",
        "            if eachObject[\"percentage_probability\"] > 65:\n",
        "              boxPoints = eachObject[\"box_points\"]\n",
        "              x1, y1, x2, y2 = boxPoints\n",
        "              top_left_x = min([x1,x2])\n",
        "              top_left_y = min([y1,y2])\n",
        "              bot_right_x = max([x1,x2])\n",
        "              bot_right_y = max([y1,y2])\n",
        "              cropped = image[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
        "              # crop,className = poseDetector.poseClassifier(cropped, loaded_model)\n",
        "              crop,className,confidence = poseDetector.poseClassifier(cropped,loaded_model)\n",
        "              if confidence is not None:                \n",
        "                confidence = max(confidence[0]) * 100\n",
        "                confidence = round(confidence,2)               \n",
        "              row = [count, person_count, eachObject[\"percentage_probability\"], className,confidence]\n",
        "              output.append(row)                \n",
        "              op_str = \"\"\n",
        "              op_str += str(className) + \":\" + str(confidence) + \"%\"\n",
        "          \n",
        "              # print(className, confidence)\n",
        "              vis_utils.draw_bounding_box_on_image(\n",
        "                          img, top_left_y, top_left_x, bot_right_y, bot_right_x,\n",
        "                          color='cyan',thickness=5,\n",
        "                          # display_str_list=[str(className),\":\",str(confidence),\"%\"],\n",
        "                          display_str_list=[op_str],\n",
        "                          use_normalized_coordinates=False\n",
        "                  )    \n",
        "              # op = filename\n",
        "              rgb_im = img.convert('RGB')\n",
        "              rgb_im.save(os.path.join(execution_path, folder_name, file_name))   \n",
        "      else:\n",
        "        success,image = vidcap.read()\n",
        "        # print(\"err\")\n",
        "          # success,image = vidcap.read()                                 # reads next frame    \n",
        "      count += 1\n",
        "\n",
        "  print(count)\n",
        "  return output"
      ],
      "metadata": {
        "id": "UluL-Jjsfvw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Aggregation\n",
        "def dataAnalyse(df):  \n",
        "  df = df.dropna()  \n",
        "  mapping = {\n",
        "    \"Hand_on_chin\" : \"Intermediate1\",\n",
        "    \"Hand_on_head\" : \"Intermediate1\",\n",
        "    \"Hand_raised\" : \"Attentive\",\n",
        "    \"Hands_Crossed\" : \"Attentive\",\n",
        "    \"Leaning_Forward\" : \"Intermediate2\",\n",
        "    \"Looking_down\" : \"Intermediate2\",\n",
        "    \"Looking_to_the_side\" : \"Inattentive\",\n",
        "    \"Sitting_Straight\" : \"Attentive\",\n",
        "    \"Sleeping\" : \"Inattentive\",\n",
        "    \"Taking_Notes\" : \"Attentive\"\n",
        "  }\n",
        "  df['Classification'] = df['Pose'].map(mapping) \n",
        "\n",
        "  # Classification percentage dataframe\n",
        "  class_data = pd.DataFrame(df['Classification'].value_counts(normalize=True) * 100)\n",
        "  dfi.export(class_data, os.path.join(download_path,'ClassTable.png'),table_conversion = 'matplotlib')\n",
        "  # Bar plot\n",
        "  ax = class_data.plot.barh(rot=0, figsize=(9, 7)).get_figure()\n",
        "  ax.savefig(os.path.join(download_path,'classBar.png'))  \n",
        "  # Pie Chart\n",
        "  plot_image = class_data.plot.pie(subplots=True, figsize=(7, 7), autopct='%1.0f%%',legend = False)[0].get_figure()   \n",
        "  plot_image.savefig(os.path.join(download_path,'classPie.png'))\n",
        "  \n",
        "  # Pose percentage dataframe\n",
        "  pose_data = pd.DataFrame(df['Pose'].value_counts(normalize=True) * 100)\n",
        "  dfi.export(pose_data, os.path.join(download_path,'PoseTable.png'),table_conversion = 'matplotlib')\n",
        "  # Bar plot\n",
        "  ax_p = pose_data.plot.barh(rot=0, figsize=(12, 9)).get_figure() \n",
        "  ax_p.savefig(os.path.join(download_path,'poseBar.png'))  \n",
        "  # Pie Chart\n",
        "  plot_image_p = pose_data.plot.pie(subplots=True, figsize=(9, 9), autopct='%1.0f%%',legend = False)[0].get_figure()\n",
        "  plot_image_p.savefig(os.path.join(download_path,'posePie.png')) \n",
        "  "
      ],
      "metadata": {
        "id": "9uOksPETBuAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createDoc():\n",
        "  \n",
        "  # Create an instance of a word document\n",
        "  doc = docx.Document()\n",
        "    \n",
        "  # Add a Title to the document\n",
        "  doc.add_heading('Attentiveness Feedback Report', 0)\n",
        "    \n",
        "  # Image in its native size\n",
        "  doc.add_heading('Classification Pie Chart', 3)\n",
        "  doc.add_picture(os.path.join(download_path,'classPie.png'), width=Inches(4), height=Inches(4))\n",
        "\n",
        "  doc.add_heading('Classification Bar Chart', 3)\n",
        "  doc.add_picture(os.path.join(download_path,'classBar.png'), width=Inches(4), height=Inches(4))\n",
        "\n",
        "  doc.add_heading('Classification table', 3)\n",
        "  doc.add_picture(os.path.join(download_path,'ClassTable.png'), width=Inches(2), height=Inches(2))\n",
        "\n",
        "  doc.add_heading('Posture Pie Chart', 3)\n",
        "  doc.add_picture(os.path.join(download_path,'posePie.png'), width=Inches(4), height=Inches(4))\n",
        "\n",
        "  doc.add_heading('Posture Bar Chart', 3)\n",
        "  doc.add_picture(os.path.join(download_path,'poseBar.png'), width=Inches(4), height=Inches(4))\n",
        "\n",
        "  doc.add_heading('Posture table', 3)\n",
        "  doc.add_picture(os.path.join(download_path,'PoseTable.png'), width=Inches(4), height=Inches(4))\n",
        "    \n",
        "  # Now save the document to a location\n",
        "  doc.save(os.path.join(download_path,'report.docx'))\n"
      ],
      "metadata": {
        "id": "Az-N2tZKQhlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createCSV(output):\n",
        "  with open(os.path.join(download_path , 'op_CSV.csv'), mode='w') as classification_file:\n",
        "      classification_writer = csv.writer(classification_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "      classification_writer.writerow([\"Frame No.\", \"Person No.\", \"Person Confidence\", \"Pose\",\"Pose Confidence\"])\n",
        "      for row in output:\n",
        "        classification_writer.writerow(row)"
      ],
      "metadata": {
        "id": "NFimuT0sYgYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main\n",
        "# inp_video = \"test2.mov\"\n",
        "# output = multiPoseClassifier(inp_video)\n",
        "# createCSV(output)\n",
        "# df = pd.DataFrame.from_records(output, columns = [\"Frame No.\", \"Person No.\", \"Person Confidence\", \"Pose\",\"Pose Confidence\"])\n",
        "# dataAnalyse(df)\n",
        "# createDoc()\n",
        "\n"
      ],
      "metadata": {
        "id": "m1OFeEG2hKv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, make_response, send_file\n",
        "from flask_cors import CORS, cross_origin\n",
        "from flask import jsonify\n",
        "import shutil\n",
        "import PIL\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "app = Flask(__name__)\n",
        "cors = CORS(app)\n",
        "app.config['CORS_HEADERS'] = 'Content-Type'\n",
        "app.config['UPLOAD_FOLDER'] = '/content/drive/MyDrive/Colab Notebooks/uploads'\n",
        "\n",
        "run_with_ngrok(app)\n",
        "\n",
        " \n",
        "\n",
        "@cross_origin()\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_file():\n",
        "    uploaded_file = request.files['file']\n",
        "    # print(uploaded_file.filename)\n",
        "    # if os.path.exists(\"drive/MyDrive/Colab Notebooks/IncreaseAccuracy/Spectrograms/uploads\") and os.path.isdir(\"drive/MyDrive/Colab Notebooks/IncreaseAccuracy/Spectrograms/uploads\"):\n",
        "    #   shutil.rmtree(\"drive/MyDrive/Colab Notebooks/IncreaseAccuracy/Spectrograms/uploads\")\n",
        "    if uploaded_file.filename != '':\n",
        "        uploaded_file.save(os.path.join(app.config['UPLOAD_FOLDER'], \"test.mov\"))\n",
        "    \n",
        "    output = multiPoseClassifier()\n",
        "    createCSV(output)\n",
        "    df = pd.DataFrame.from_records(output, columns = [\"Frame No.\", \"Person No.\", \"Person Confidence\", \"Pose\",\"Pose Confidence\"])\n",
        "    dataAnalyse(df)\n",
        "    createDoc()        \n",
        "\n",
        "    fid1 = getoutput(\"xattr -p 'user.drive.id' '/content/drive/My Drive/Colab Notebooks/downloads/classPie.png' \")\n",
        "    fid2 = getoutput(\"xattr -p 'user.drive.id' '/content/drive/My Drive/Colab Notebooks/downloads/posePie.png' \")\n",
        "    fid3 = getoutput(\"xattr -p 'user.drive.id' '/content/drive/My Drive/Colab Notebooks/downloads/classBar.png' \")\n",
        "    fid4 = getoutput(\"xattr -p 'user.drive.id' '/content/drive/My Drive/Colab Notebooks/downloads/poseBar.png' \")\n",
        "    fid5 = getoutput(\"xattr -p 'user.drive.id' '/content/drive/My Drive/Colab Notebooks/downloads/report.docx' \")\n",
        "    response  = {\"files\":[fid1,fid2,fid3,fid4,fid5]}\n",
        "    return response\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  app.run()"
      ],
      "metadata": {
        "id": "61QQkoJxqeKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  # access drive\n",
        "# # need to install xattr\n",
        "\n",
        "# # get the id\n",
        "# fid = getoutput(\"xattr -p 'user.drive.id' '/content/drive/My Drive/Colab Notebooks/downloads/classBar.png' \")\n",
        "# print(fid)\n",
        "# print(\"1-_6lTGybYp3EToNPa3Kt2rmH1GL6evKy\")\n",
        "# # make a link and display it\n",
        "# HTML(f\"<a href=https://colab.research.google.com/drive/{fid} target=_blank>notebook</a>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "w9hZUKlO8S4d",
        "outputId": "00e8f89a-df0f-489b-eb0f-29ee0dab67ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "1-_6lTGybYp3EToNPa3Kt2rmH1GL6evKy\n",
            "1-_6lTGybYp3EToNPa3Kt2rmH1GL6evKy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=https://colab.research.google.com/drive/1-_6lTGybYp3EToNPa3Kt2rmH1GL6evKy target=_blank>notebook</a>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import os\n",
        "# execution_path = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "# op = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/res.csv')\n",
        "# # ct, pt = dataAnalyse(op)\n",
        "# pie_class , bar_class, pie_pose, bar_pose, ct, pt = dataAnalyse(op)\n",
        "# # type(pie_class)\n",
        "\n",
        "# f_img = \"drive/MyDrive/Colab Notebooks/IncreaseAccuracy/Spectrograms/uploads/upload.png\"\n",
        "    # img1 = Image.open(os.path.join(download_path,'classPie.png'))\n",
        "    # img2 = Image.open(os.path.join(download_path,'classBar.png'))\n",
        "    # img3 = Image.open(os.path.join(download_path,'posePie.png'))\n",
        "    # img4 = Image.open(os.path.join(download_path,'poseBar.png'))\n",
        "\n",
        "    # img_list = [img1, img2, img3, img4]\n",
        "    # doc = os.path.join(download_path,'report.docx')\n",
        "\n",
        "    # # return send_file(os.path.join(download_path,'classPie.png'), mimetype='image/png')\n",
        "\n",
        "    # ##reuslt  contains list of path images\n",
        "    # result = [os.path.join(download_path,'classPie.png'),os.path.join(download_path,'classBar.png'),os.path.join(download_path,'posePie.png'),os.path.join(download_path,'poseBar.png')]\n",
        "    # encoded_imges = []\n",
        "    # for image_path in result:\n",
        "    #     encoded_imges.append(get_response_image(image_path))\n",
        "    # return jsonify({'result': encoded_imges})"
      ],
      "metadata": {
        "id": "uVcWfS0Y2K_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}